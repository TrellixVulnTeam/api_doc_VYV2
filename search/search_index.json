{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Laying the foundations for video intelligence \u00b6 Chrysalis is the first seamless, low-cost video streaming platform that enables real-time video analytics on the edge or in the cloud. The Chrysalis Edge Proxy provides a simple, common interface for conducting AI operations on or near the edge from multiple camera sources. The Chrysalis Cloud provides a simple, common interface for conducting AI operations in the cloud and enables extracting valuable information from video sources streaming directly to our cloud or from the edge The Chrysalis Cloud Management Console Simple and user friendly interface for managing and monitoring your edge fleet as well as cloud resources. Get more information about the company here","title":"Home"},{"location":"#laying-the-foundations-for-video-intelligence","text":"Chrysalis is the first seamless, low-cost video streaming platform that enables real-time video analytics on the edge or in the cloud. The Chrysalis Edge Proxy provides a simple, common interface for conducting AI operations on or near the edge from multiple camera sources. The Chrysalis Cloud provides a simple, common interface for conducting AI operations in the cloud and enables extracting valuable information from video sources streaming directly to our cloud or from the edge The Chrysalis Cloud Management Console Simple and user friendly interface for managing and monitoring your edge fleet as well as cloud resources. Get more information about the company here","title":"Laying the foundations for video intelligence"},{"location":"cedge/","text":"Chrysalis Cloud Video-Edge-AI-Proxy \u00b6 The ultimate video pipeline for Computer Vision. The video-edge-ai-proxy ingests multiple RTSP camera streams and provides a common interface for conducting AI operations on or near the Edge. The video-edge-ai-proxy is an easy to use collection mechanism from multiple cameras onto a single more powerful computer. For example, a network of CCTV RTSP enabled cameras can be accessed through a simple GRPC interface, where Machine Learning algorithms can do various Computer Vision tasks. Furthermore, interesting footage can be annotated, selectively streamed and stored through a simple API for later analysis, computer vision tasks in the cloud or enriching the Machine Learning training samples.","title":"Chrysalis Cloud Video-Edge-AI-Proxy"},{"location":"cedge/#chrysalis-cloud-video-edge-ai-proxy","text":"The ultimate video pipeline for Computer Vision. The video-edge-ai-proxy ingests multiple RTSP camera streams and provides a common interface for conducting AI operations on or near the Edge. The video-edge-ai-proxy is an easy to use collection mechanism from multiple cameras onto a single more powerful computer. For example, a network of CCTV RTSP enabled cameras can be accessed through a simple GRPC interface, where Machine Learning algorithms can do various Computer Vision tasks. Furthermore, interesting footage can be annotated, selectively streamed and stored through a simple API for later analysis, computer vision tasks in the cloud or enriching the Machine Learning training samples.","title":"Chrysalis Cloud Video-Edge-AI-Proxy"},{"location":"edge-proxy/homepage/","text":"Chrysalis Cloud Video-Edge-AI-Proxy \u00b6 The ultimate video pipeline for Computer Vision. The video-edge-ai-proxy ingests multiple RTSP camera streams and provides a common interface for conducting AI operations on or near the Edge. The video-edge-ai-proxy is an easy to use collection mechanism from multiple cameras onto a single more powerful computer. For example, a network of CCTV RTSP enabled cameras can be accessed through a simple GRPC interface, where Machine Learning algorithms can do various Computer Vision tasks. Furthermore, interesting footage can be annotated, selectively streamed and stored through a simple API for later analysis, computer vision tasks in the cloud or enriching the Machine Learning training samples. Features \u00b6 Build with AI inference in mind. Basic Features Camera HUB User interface and RESTful API for setting up multiple RTSP cameras Connection management Handles cases of network fluctuations or camera streaming problems Stream management Deals with the complexities of compressed video streams so you don't have to Video/Image Hub Processing multiple camera sources simultaneously Flexibility Can support other than RTSP cameras Connection to Cloud Selective Pass-Through Preserving bandwidth by choosing when to forward a portion of a stream to the cloud Storage optimizer Minimizing video by selecting which portions of stream to store in the cloud AI Annotation Asynchronous annotations to the cloud","title":"About"},{"location":"edge-proxy/homepage/#chrysalis-cloud-video-edge-ai-proxy","text":"The ultimate video pipeline for Computer Vision. The video-edge-ai-proxy ingests multiple RTSP camera streams and provides a common interface for conducting AI operations on or near the Edge. The video-edge-ai-proxy is an easy to use collection mechanism from multiple cameras onto a single more powerful computer. For example, a network of CCTV RTSP enabled cameras can be accessed through a simple GRPC interface, where Machine Learning algorithms can do various Computer Vision tasks. Furthermore, interesting footage can be annotated, selectively streamed and stored through a simple API for later analysis, computer vision tasks in the cloud or enriching the Machine Learning training samples.","title":"Chrysalis Cloud Video-Edge-AI-Proxy"},{"location":"edge-proxy/homepage/#features","text":"Build with AI inference in mind. Basic Features Camera HUB User interface and RESTful API for setting up multiple RTSP cameras Connection management Handles cases of network fluctuations or camera streaming problems Stream management Deals with the complexities of compressed video streams so you don't have to Video/Image Hub Processing multiple camera sources simultaneously Flexibility Can support other than RTSP cameras Connection to Cloud Selective Pass-Through Preserving bandwidth by choosing when to forward a portion of a stream to the cloud Storage optimizer Minimizing video by selecting which portions of stream to store in the cloud AI Annotation Asynchronous annotations to the cloud","title":"Features"},{"location":"edge-proxy/apis/rest_api_curl/","text":"Chrysalis Clouds' REST APIs \u00b6 The Chrysalis Clouds' video-edge-ai-proxy server exposes RESTful APIs for stream management. With these APIs you can start, stop, delete, and list the rtmp_to_rtsp containers. Connect \u00b6 This commands lets you connet to a new RTSP camera. curl curl -d '{\"name\":\"demo\",\"rtsp_endpoint\":\"rtsp://igor:igor123456@10.0.1.26/axis-media/media.amp\"}' -H \"Content-Type:application/json\" http://127.0.0.1:8909/api/v1/process Get process \u00b6 This command will return the details of a single RTSP camera process curl curl http://127.0.0.1:8909/api/v1/process/{processName} Path Parameters \u00b6 Parameters processName string The name of the RTSP process. For example: demo Response Body \u00b6 { \"container_id\" : \"d8e821530a1841db8aa29830bba1849b95fdedbc255b0ee2063f225cf7ce2425\" , \"created\" : 1610394856000 , \"image_tag\" : \"chryscloud/chrysedgeproxy:0.0.6\" , \"logs\" : { \"stderr\" : null , \"stdout\" : \"QXJjaG...\" }, \"modified\" : 1610394893000 , \"name\" : \"demo\" , \"rtmp_stream_status\" : { \"storing\" : false , \"streaming\" : true }, \"rtsp_endpoint\" : \"rtsp://igor:igor123456@10.0.1.26/axis-media/media.amp\" , \"state\" : { \"Dead\" : false , \"Error\" : \"\" , \"ExitCode\" : 0 , \"FinishedAt\" : \"0001-01-01T00:00:00Z\" , \"OOMKilled\" : false , \"Paused\" : false , \"Pid\" : 122478 , \"Restarting\" : false , \"Running\" : true , \"StartedAt\" : \"2021-01-11T19:54:16.01726981Z\" , \"Status\" : \"running\" }, \"status\" : \"running\" , \"upgrade_available\" : false } Fields container_id string : The id of the tunning docker container created int64 : milliseconds since epoch this process was created image_tag string : name of the docker image for the current process logs Logs modified int64 : milliseconds since epoch of the last modification to this process name string : name of the process rtmp_stream_status RtmpStreamStatus rtsp_endpoint string : full connection string for the RTSP camera status string : the status of the process: running , paused , oomkilled , restarting , created upgrade_available bool : If the new version for this process is available Logs \u00b6 Field stderr base64 : base64 encoded standard output errors from the process stdout base64 : base64 encoded standard output from the process RtmpStreamStatus \u00b6 Field storing bool : if the current process is storing the video stream in the cloud streaming bool : if the current process is proxying the video stream to the cloud Start \u00b6 This command lets you start a RTSP camera process. curl curl -X POST http://127.0.0.1:8909/api/v1/process/startrtsp Stop \u00b6 This command lets you stop a RTSP camera process. curl curl -X DELETE http://127.0.0.1:8909/api/v1/process/stop/{processName} Info \u00b6 This commands fetches information about the RTSP camera process curl curl -X GET http://127.0.0.1:8909/api/v1/process/info/{processName} Response Body \u00b6 { Example here } Delete \u00b6 This command lets you delete a RTSP camera. curl curl -X DELETE http://127.0.0.1:8909/api/v1/process/{processName} List \u00b6 This command lists all the RTSP cameras. curl curl http://127.0.0.1:8909/api/v1/processlist Find RTSP Upgrades \u00b6 This command checks if each process has an upgradable version available on local disk curl curl http://127.0.0.1:8909/api/v1/processupgrades/findrtspupgrades UpgradeContainer \u00b6 This commands lets you upgrade a running container curl curl -X POST http://127.0.0.1:8909/api/v1/processupgrades/upgradecontainer Get Settings \u00b6 This command lets you get settings from the sttings manager curl curl -X GET http://127.0.0.1:8909/api/v1/settings/ Overwrite Settings \u00b6 This commands lets you overwrite setting in the settings manager curl curl -X POST http://127.0.0.1:8909/api/v1/settings/overwrite/{edgeParams} Path Parameters \u00b6 Parameters edgeParams string The Edge Key and the Edge Secret??!!! Docker Pull Image \u00b6 This command lets you pull the latest docker image curl curl -X GET http://127.0.0.1:8909/api/v1/settings/dockerpullimage Find Docker Images \u00b6 This command finds images that correspond with the docker image name and returns if its downloaded or maybe if upgraded is needed curl curl -X GET http://127.0.0.1:8909/api/v1/settings/dockerimageslocally/{image_name} Path Parameters \u00b6 Parameters image_name string The name of the docker image","title":"REST API"},{"location":"edge-proxy/apis/rest_api_curl/#chrysalis-clouds-rest-apis","text":"The Chrysalis Clouds' video-edge-ai-proxy server exposes RESTful APIs for stream management. With these APIs you can start, stop, delete, and list the rtmp_to_rtsp containers.","title":"Chrysalis Clouds' REST APIs"},{"location":"edge-proxy/apis/rest_api_curl/#connect","text":"This commands lets you connet to a new RTSP camera. curl curl -d '{\"name\":\"demo\",\"rtsp_endpoint\":\"rtsp://igor:igor123456@10.0.1.26/axis-media/media.amp\"}' -H \"Content-Type:application/json\" http://127.0.0.1:8909/api/v1/process","title":"Connect"},{"location":"edge-proxy/apis/rest_api_curl/#get-process","text":"This command will return the details of a single RTSP camera process curl curl http://127.0.0.1:8909/api/v1/process/{processName}","title":"Get process"},{"location":"edge-proxy/apis/rest_api_curl/#path-parameters","text":"Parameters processName string The name of the RTSP process. For example: demo","title":"Path Parameters"},{"location":"edge-proxy/apis/rest_api_curl/#response-body","text":"{ \"container_id\" : \"d8e821530a1841db8aa29830bba1849b95fdedbc255b0ee2063f225cf7ce2425\" , \"created\" : 1610394856000 , \"image_tag\" : \"chryscloud/chrysedgeproxy:0.0.6\" , \"logs\" : { \"stderr\" : null , \"stdout\" : \"QXJjaG...\" }, \"modified\" : 1610394893000 , \"name\" : \"demo\" , \"rtmp_stream_status\" : { \"storing\" : false , \"streaming\" : true }, \"rtsp_endpoint\" : \"rtsp://igor:igor123456@10.0.1.26/axis-media/media.amp\" , \"state\" : { \"Dead\" : false , \"Error\" : \"\" , \"ExitCode\" : 0 , \"FinishedAt\" : \"0001-01-01T00:00:00Z\" , \"OOMKilled\" : false , \"Paused\" : false , \"Pid\" : 122478 , \"Restarting\" : false , \"Running\" : true , \"StartedAt\" : \"2021-01-11T19:54:16.01726981Z\" , \"Status\" : \"running\" }, \"status\" : \"running\" , \"upgrade_available\" : false } Fields container_id string : The id of the tunning docker container created int64 : milliseconds since epoch this process was created image_tag string : name of the docker image for the current process logs Logs modified int64 : milliseconds since epoch of the last modification to this process name string : name of the process rtmp_stream_status RtmpStreamStatus rtsp_endpoint string : full connection string for the RTSP camera status string : the status of the process: running , paused , oomkilled , restarting , created upgrade_available bool : If the new version for this process is available","title":"Response Body"},{"location":"edge-proxy/apis/rest_api_curl/#logs","text":"Field stderr base64 : base64 encoded standard output errors from the process stdout base64 : base64 encoded standard output from the process","title":"Logs"},{"location":"edge-proxy/apis/rest_api_curl/#rtmpstreamstatus","text":"Field storing bool : if the current process is storing the video stream in the cloud streaming bool : if the current process is proxying the video stream to the cloud","title":"RtmpStreamStatus"},{"location":"edge-proxy/apis/rest_api_curl/#start","text":"This command lets you start a RTSP camera process. curl curl -X POST http://127.0.0.1:8909/api/v1/process/startrtsp","title":"Start"},{"location":"edge-proxy/apis/rest_api_curl/#stop","text":"This command lets you stop a RTSP camera process. curl curl -X DELETE http://127.0.0.1:8909/api/v1/process/stop/{processName}","title":"Stop"},{"location":"edge-proxy/apis/rest_api_curl/#info","text":"This commands fetches information about the RTSP camera process curl curl -X GET http://127.0.0.1:8909/api/v1/process/info/{processName}","title":"Info"},{"location":"edge-proxy/apis/rest_api_curl/#response-body_1","text":"{ Example here }","title":"Response Body"},{"location":"edge-proxy/apis/rest_api_curl/#delete","text":"This command lets you delete a RTSP camera. curl curl -X DELETE http://127.0.0.1:8909/api/v1/process/{processName}","title":"Delete"},{"location":"edge-proxy/apis/rest_api_curl/#list","text":"This command lists all the RTSP cameras. curl curl http://127.0.0.1:8909/api/v1/processlist","title":"List"},{"location":"edge-proxy/apis/rest_api_curl/#find-rtsp-upgrades","text":"This command checks if each process has an upgradable version available on local disk curl curl http://127.0.0.1:8909/api/v1/processupgrades/findrtspupgrades","title":"Find RTSP Upgrades"},{"location":"edge-proxy/apis/rest_api_curl/#upgradecontainer","text":"This commands lets you upgrade a running container curl curl -X POST http://127.0.0.1:8909/api/v1/processupgrades/upgradecontainer","title":"UpgradeContainer"},{"location":"edge-proxy/apis/rest_api_curl/#get-settings","text":"This command lets you get settings from the sttings manager curl curl -X GET http://127.0.0.1:8909/api/v1/settings/","title":"Get Settings"},{"location":"edge-proxy/apis/rest_api_curl/#overwrite-settings","text":"This commands lets you overwrite setting in the settings manager curl curl -X POST http://127.0.0.1:8909/api/v1/settings/overwrite/{edgeParams}","title":"Overwrite Settings"},{"location":"edge-proxy/apis/rest_api_curl/#path-parameters_1","text":"Parameters edgeParams string The Edge Key and the Edge Secret??!!!","title":"Path Parameters"},{"location":"edge-proxy/apis/rest_api_curl/#docker-pull-image","text":"This command lets you pull the latest docker image curl curl -X GET http://127.0.0.1:8909/api/v1/settings/dockerpullimage","title":"Docker Pull Image"},{"location":"edge-proxy/apis/rest_api_curl/#find-docker-images","text":"This command finds images that correspond with the docker image name and returns if its downloaded or maybe if upgraded is needed curl curl -X GET http://127.0.0.1:8909/api/v1/settings/dockerimageslocally/{image_name}","title":"Find Docker Images"},{"location":"edge-proxy/apis/rest_api_curl/#path-parameters_2","text":"Parameters image_name string The name of the docker image","title":"Path Parameters"},{"location":"edge-proxy/build-from-source/bfs/","text":"Building from source \u00b6 Clone repository \u00b6 Clone the Chrysalis Cloud video-edge-ai-proxy repo from guthub: git clone https://github.com/chryscloud/video-edge-ai-proxy.git The video-edge-ai-proxy stores running processes, one for each connected camera, into a local datastore hosted on your file system. By default the folder path used is: /data/chrysalis create this folder if it doesn't exist and make sure it's writable by docker process. Docker run \u00b6 In case you cloned this repository you can run docker-compose with build command. Start video-edge-ai-proxy with local build: docker-compose up -d or docker-compose build","title":"Building from Source"},{"location":"edge-proxy/build-from-source/bfs/#building-from-source","text":"","title":"Building from source"},{"location":"edge-proxy/build-from-source/bfs/#clone-repository","text":"Clone the Chrysalis Cloud video-edge-ai-proxy repo from guthub: git clone https://github.com/chryscloud/video-edge-ai-proxy.git The video-edge-ai-proxy stores running processes, one for each connected camera, into a local datastore hosted on your file system. By default the folder path used is: /data/chrysalis create this folder if it doesn't exist and make sure it's writable by docker process.","title":"Clone repository"},{"location":"edge-proxy/build-from-source/bfs/#docker-run","text":"In case you cloned this repository you can run docker-compose with build command. Start video-edge-ai-proxy with local build: docker-compose up -d or docker-compose build","title":"Docker run"},{"location":"edge-proxy/custom-configuration/chrysalis-config/","text":"Custom Chrysalis configuration \u00b6 Create conf.yaml file in the location: Linux Place conf.yaml into \"data\" folder: e.g. /home/yourusername/chrysedge/data folder Mac OS X Place conf.yaml into \"data\" folder: e.g. /home/yourusername/chrysedge/data folder Windows Place conf.yaml into \"data\" folder: e.g. /c/yourfolder/chrysedge/data folder on_disk_folder by prefixing with /C/ Example: on_disk_folder: /C/Users/user/chrys-video-egde-proxy/videos The configuration file is automatically picked up if it exists otherwise system fallbacks to it's default configuration. Configuration \u00b6 version: 0.0.7 title: Chrysalis Video Edge Proxy description: Chrysalis Video Edge Proxy Service for Computer Vision mode: release # \"debug\": or \"release\" redis: connection: \"redis:6379\" database: 0 password: \"\" api: endpoint: https://api.chryscloud.com annotation: endpoint: \"https://event.chryscloud.com/api/v1/annotate\" unacked_limit: 1000 poll_duration_ms: 300 max_batch_size: 299 buffer: in_memory: 100 # number of buffed images per camera in_memory_scale: \"iw/2:ih/2\" # scaling of the images. Examples: 400:-1 (keeps aspect radio with width 400), 400:300, iw/3:ih/3, ...) on_disk: false # store key-frame separated mp4 file segments to disk on_disk_folder: /home/yourusername/chrysedge/data # can be any custom folder you'd like to store video segments to on_disk_clean_older_than: \"5m\" # remove older mp4 segments than 5m mode: release : disables debug mode for http server (default: release) redis -> connection : redis host with port (default: \"redis:6379\") redis -> database : 0 - 15. 0 is redis default database. (default: 0) redis -> password : optional redis password (default: \"\") api -> endpoint : chrysalis API location for remote signaling such as enable/disable storage (default: https://api.chryscloud.com ) annotation -> endpoint : Crysalis Cloud annotation endpoint (default: https://event.chryscloud.com/api/v1/annotate ) annotation -> unacked limit : maximum number of unacknowledged annotatoons (default: 299) annotation -> poll_duration_ms : poll every x miliseconds for batching purposes (default: 300ms) annotation -> max_match_size : maximum number of annotation per batch size (default: 299) buffer -> in_memory : number of decoded frames in video buffer per camera in_memory_scale : iw/2:ih/2 # scaling of the buffered frames. Examples: 400:-1 (keeps aspect radio with width 400), 400:300, iw/3:ih/3, ...) on_disk : true/false, store key-frame chunked mp4 files to disk (default: false) on_disk_folder : path to the folder where segments will be stored on_disk_clean_older_than : remove mp4 segments older than (default: 5m) on_disk_schedule : run disk cleanup scheduler cron job #https://en.wikipedia.org/wiki/Cron on_disk creates mp4 segments in format: \"current_timestamp in ms\"_\"duration_in_ms\".mp4 . For example: 1600685088000_2000.mp4","title":"Custom Chrysalis configuration"},{"location":"edge-proxy/custom-configuration/chrysalis-config/#custom-chrysalis-configuration","text":"Create conf.yaml file in the location: Linux Place conf.yaml into \"data\" folder: e.g. /home/yourusername/chrysedge/data folder Mac OS X Place conf.yaml into \"data\" folder: e.g. /home/yourusername/chrysedge/data folder Windows Place conf.yaml into \"data\" folder: e.g. /c/yourfolder/chrysedge/data folder on_disk_folder by prefixing with /C/ Example: on_disk_folder: /C/Users/user/chrys-video-egde-proxy/videos The configuration file is automatically picked up if it exists otherwise system fallbacks to it's default configuration.","title":"Custom Chrysalis configuration"},{"location":"edge-proxy/custom-configuration/chrysalis-config/#configuration","text":"version: 0.0.7 title: Chrysalis Video Edge Proxy description: Chrysalis Video Edge Proxy Service for Computer Vision mode: release # \"debug\": or \"release\" redis: connection: \"redis:6379\" database: 0 password: \"\" api: endpoint: https://api.chryscloud.com annotation: endpoint: \"https://event.chryscloud.com/api/v1/annotate\" unacked_limit: 1000 poll_duration_ms: 300 max_batch_size: 299 buffer: in_memory: 100 # number of buffed images per camera in_memory_scale: \"iw/2:ih/2\" # scaling of the images. Examples: 400:-1 (keeps aspect radio with width 400), 400:300, iw/3:ih/3, ...) on_disk: false # store key-frame separated mp4 file segments to disk on_disk_folder: /home/yourusername/chrysedge/data # can be any custom folder you'd like to store video segments to on_disk_clean_older_than: \"5m\" # remove older mp4 segments than 5m mode: release : disables debug mode for http server (default: release) redis -> connection : redis host with port (default: \"redis:6379\") redis -> database : 0 - 15. 0 is redis default database. (default: 0) redis -> password : optional redis password (default: \"\") api -> endpoint : chrysalis API location for remote signaling such as enable/disable storage (default: https://api.chryscloud.com ) annotation -> endpoint : Crysalis Cloud annotation endpoint (default: https://event.chryscloud.com/api/v1/annotate ) annotation -> unacked limit : maximum number of unacknowledged annotatoons (default: 299) annotation -> poll_duration_ms : poll every x miliseconds for batching purposes (default: 300ms) annotation -> max_match_size : maximum number of annotation per batch size (default: 299) buffer -> in_memory : number of decoded frames in video buffer per camera in_memory_scale : iw/2:ih/2 # scaling of the buffered frames. Examples: 400:-1 (keeps aspect radio with width 400), 400:300, iw/3:ih/3, ...) on_disk : true/false, store key-frame chunked mp4 files to disk (default: false) on_disk_folder : path to the folder where segments will be stored on_disk_clean_older_than : remove mp4 segments older than (default: 5m) on_disk_schedule : run disk cleanup scheduler cron job #https://en.wikipedia.org/wiki/Cron on_disk creates mp4 segments in format: \"current_timestamp in ms\"_\"duration_in_ms\".mp4 . For example: 1600685088000_2000.mp4","title":"Configuration"},{"location":"edge-proxy/custom-configuration/redis-config/","text":"Custom redis configuration \u00b6 Default configuration is in the root folder of the project: ./redis.conf Update default redis.conf in the root directory of the project Uncomment volumes section in redis config # volumes: # - /data/chrysalis/redis:/data # - ./redis.conf:/usr/local/etc/redis/redis.conf # command: # - redis-server # - /usr/local/etc/redis/redis.conf Modify folders accordingly for Mac OS X and Windows","title":"Custom redis configuration"},{"location":"edge-proxy/custom-configuration/redis-config/#custom-redis-configuration","text":"Default configuration is in the root folder of the project: ./redis.conf Update default redis.conf in the root directory of the project Uncomment volumes section in redis config # volumes: # - /data/chrysalis/redis:/data # - ./redis.conf:/usr/local/etc/redis/redis.conf # command: # - redis-server # - /usr/local/etc/redis/redis.conf Modify folders accordingly for Mac OS X and Windows","title":"Custom redis configuration"},{"location":"edge-proxy/examples/basic-usage/","text":"Listing connected cameras \u00b6 This example displays all connected cameras to Chrysalis Edge. It's a simple request, response Unary RPC call. list_streams.py: import grpc import video_streaming_pb2_grpc , video_streaming_pb2 import argparse def send_list_stream_request ( stub ): \"\"\" Create a list of streams request object \"\"\" stream_request = video_streaming_pb2 . ListStreamRequest () responses = stub . ListStreams ( stream_request ) for stream_resp in responses : yield stream_resp if __name__ == \"__main__\" : # grpc connection to video-edge-ai-proxy options = [( 'grpc.max_receive_message_length' , 50 * 1024 * 1024 )] # 50 MB max single response channel = grpc . insecure_channel ( '127.0.0.1:50001' , options = options ) stub = video_streaming_pb2_grpc . ImageStub ( channel ) # send request list_streams = send_list_stream_request ( stub ) for stream in list_streams : print ( stream ) List all stream processes: python list_streams.py Successful output example: name: \"test\" status: \"running\" pid: 18109 running: true","title":"List Cameras"},{"location":"edge-proxy/examples/basic-usage/#listing-connected-cameras","text":"This example displays all connected cameras to Chrysalis Edge. It's a simple request, response Unary RPC call. list_streams.py: import grpc import video_streaming_pb2_grpc , video_streaming_pb2 import argparse def send_list_stream_request ( stub ): \"\"\" Create a list of streams request object \"\"\" stream_request = video_streaming_pb2 . ListStreamRequest () responses = stub . ListStreams ( stream_request ) for stream_resp in responses : yield stream_resp if __name__ == \"__main__\" : # grpc connection to video-edge-ai-proxy options = [( 'grpc.max_receive_message_length' , 50 * 1024 * 1024 )] # 50 MB max single response channel = grpc . insecure_channel ( '127.0.0.1:50001' , options = options ) stub = video_streaming_pb2_grpc . ImageStub ( channel ) # send request list_streams = send_list_stream_request ( stub ) for stream in list_streams : print ( stream ) List all stream processes: python list_streams.py Successful output example: name: \"test\" status: \"running\" pid: 18109 running: true","title":"Listing connected cameras"},{"location":"edge-proxy/examples/display/","text":"Displaying live video stream with OpenCV \u00b6 Example demonstrated displaying a live video stream and probing in memory buffer if it exists. opencv_display.py: import grpc import video_streaming_pb2_grpc , video_streaming_pb2 import argparse import cv2 import numpy as np import time import os def gen_buffer_probe_request ( device_name ): \"\"\" Create GRPC request to get in memory probe info \"\"\" req = video_streaming_pb2 . VideoProbeRequest () req . device_id = device_name return req def gen_image_request ( device_name , keyframe_only ): \"\"\" Create an object to request a video frame \"\"\" req = video_streaming_pb2 . VideoFrameRequest () req . device_id = device_name req . key_frame_only = keyframe_only return req if __name__ == \"__main__\" : parser = argparse . ArgumentParser ( description = 'Chrysalis Edge Proxy Basic Example' ) parser . add_argument ( \"--device\" , type = str , default = None , required = True ) parser . add_argument ( \"--keyframe\" , action = 'store_true' ) args = parser . parse_args () # grpc connection to video-edge-ai-proxy # we also increase the limit of decoded frames (up to 50 MB for super high definition videos) options = [( 'grpc.max_receive_message_length' , 50 * 1024 * 1024 )] channel = grpc . insecure_channel ( '127.0.0.1:50001' , options = options ) stub = video_streaming_pb2_grpc . ImageStub ( channel ) # displaying video info (if exists) probe = stub . VideoProbe ( gen_buffer_probe_request ( device_name = args . device )) aproxFps = 30 # just a guess if probe . buffer : aproxFps = probe . buffer . approximate_fps print ( probe ) # requesting video frames req = gen_image_request ( device_name = args . device , keyframe_only = args . keyframe ) while True : frame = stub . VideoLatestImage ( req ) # it's good to check if empty frame returned if frame is not None : # read raw frame data and convert to numpy array img_bytes = frame . data re_img = np . frombuffer ( img_bytes , dtype = np . uint8 ) # reshape image back into original dimensions if len ( frame . shape . dim ) > 0 : reshape = tuple ([ int ( dim . size ) for dim in frame . shape . dim ]) re_img = np . reshape ( re_img , reshape ) # # display image cv2 . imshow ( 'box' , re_img ) if cv2 . waitKey ( 1 ) & 0xFF == ord ( 'q' ): break # delay by assumed fps rate delay = 1 / aproxFps time . sleep ( delay ) Display video at original frame rate for test camera: python opencv_display.py --device test Display only Keyframes for test camera: python opencv_display.py --device test --keyframe Code walkthrough \u00b6 We establish a gRPC connection to Chryslis Edge Proxy which by default runs on :50001 port of locahost: # grpc connection to video-edge-ai-proxy # we also increase the limit of decoded frames (up to 50 MB for super high definition videos) options = [( 'grpc.max_receive_message_length' , 50 * 1024 * 1024 )] channel = grpc . insecure_channel ( '127.0.0.1:50001' , options = options ) stub = video_streaming_pb2_grpc . ImageStub ( channel ) Once we've established the connection we need to create a frame request to be sent to server: def gen_image_request ( device_name , keyframe_only ): \"\"\" Create an object to request a video frame \"\"\" req = video_streaming_pb2 . VideoFrameRequest () req . device_id = device_name req . key_frame_only = keyframe_only return req Function accepts 2 parameters (device_name, sometimes referred to as device_id or camera name) and keyframe_only requesting only keyframes when True. In perpetual loop we request video frames for desired camera. It's a simple request, response Unary RPC call. # requesting video frames req = gen_image_request ( device_name = args . device , keyframe_only = args . keyframe ) while True : frame = stub . VideoLatestImage ( req ) # it's good to check if empty frame returned if frame is not None : # read raw frame data and convert to numpy array img_bytes = frame . data re_img = np . frombuffer ( img_bytes , dtype = np . uint8 ) Returned frame from VideoLatestImage contains a data attribute. That's where our image is stored as BGR24 file. Since the data is stored as one dimensional byte buffer we need to convert the image into numpy array. After we converted the image into numpy array is easy to reshape that array into a decoded frame dimensions: # reshape image back into original dimensions if len ( frame . shape . dim ) > 0 : reshape = tuple ([ int ( dim . size ) for dim in frame . shape . dim ]) re_img = np . reshape ( re_img , reshape ) We end up with BGR24 image ready to be fed into any ML model or displayed with OpenCV as in our case: # display image cv2 . imshow ( 'box' , re_img )","title":"Display Video"},{"location":"edge-proxy/examples/display/#displaying-live-video-stream-with-opencv","text":"Example demonstrated displaying a live video stream and probing in memory buffer if it exists. opencv_display.py: import grpc import video_streaming_pb2_grpc , video_streaming_pb2 import argparse import cv2 import numpy as np import time import os def gen_buffer_probe_request ( device_name ): \"\"\" Create GRPC request to get in memory probe info \"\"\" req = video_streaming_pb2 . VideoProbeRequest () req . device_id = device_name return req def gen_image_request ( device_name , keyframe_only ): \"\"\" Create an object to request a video frame \"\"\" req = video_streaming_pb2 . VideoFrameRequest () req . device_id = device_name req . key_frame_only = keyframe_only return req if __name__ == \"__main__\" : parser = argparse . ArgumentParser ( description = 'Chrysalis Edge Proxy Basic Example' ) parser . add_argument ( \"--device\" , type = str , default = None , required = True ) parser . add_argument ( \"--keyframe\" , action = 'store_true' ) args = parser . parse_args () # grpc connection to video-edge-ai-proxy # we also increase the limit of decoded frames (up to 50 MB for super high definition videos) options = [( 'grpc.max_receive_message_length' , 50 * 1024 * 1024 )] channel = grpc . insecure_channel ( '127.0.0.1:50001' , options = options ) stub = video_streaming_pb2_grpc . ImageStub ( channel ) # displaying video info (if exists) probe = stub . VideoProbe ( gen_buffer_probe_request ( device_name = args . device )) aproxFps = 30 # just a guess if probe . buffer : aproxFps = probe . buffer . approximate_fps print ( probe ) # requesting video frames req = gen_image_request ( device_name = args . device , keyframe_only = args . keyframe ) while True : frame = stub . VideoLatestImage ( req ) # it's good to check if empty frame returned if frame is not None : # read raw frame data and convert to numpy array img_bytes = frame . data re_img = np . frombuffer ( img_bytes , dtype = np . uint8 ) # reshape image back into original dimensions if len ( frame . shape . dim ) > 0 : reshape = tuple ([ int ( dim . size ) for dim in frame . shape . dim ]) re_img = np . reshape ( re_img , reshape ) # # display image cv2 . imshow ( 'box' , re_img ) if cv2 . waitKey ( 1 ) & 0xFF == ord ( 'q' ): break # delay by assumed fps rate delay = 1 / aproxFps time . sleep ( delay ) Display video at original frame rate for test camera: python opencv_display.py --device test Display only Keyframes for test camera: python opencv_display.py --device test --keyframe","title":"Displaying live video stream with OpenCV"},{"location":"edge-proxy/examples/display/#code-walkthrough","text":"We establish a gRPC connection to Chryslis Edge Proxy which by default runs on :50001 port of locahost: # grpc connection to video-edge-ai-proxy # we also increase the limit of decoded frames (up to 50 MB for super high definition videos) options = [( 'grpc.max_receive_message_length' , 50 * 1024 * 1024 )] channel = grpc . insecure_channel ( '127.0.0.1:50001' , options = options ) stub = video_streaming_pb2_grpc . ImageStub ( channel ) Once we've established the connection we need to create a frame request to be sent to server: def gen_image_request ( device_name , keyframe_only ): \"\"\" Create an object to request a video frame \"\"\" req = video_streaming_pb2 . VideoFrameRequest () req . device_id = device_name req . key_frame_only = keyframe_only return req Function accepts 2 parameters (device_name, sometimes referred to as device_id or camera name) and keyframe_only requesting only keyframes when True. In perpetual loop we request video frames for desired camera. It's a simple request, response Unary RPC call. # requesting video frames req = gen_image_request ( device_name = args . device , keyframe_only = args . keyframe ) while True : frame = stub . VideoLatestImage ( req ) # it's good to check if empty frame returned if frame is not None : # read raw frame data and convert to numpy array img_bytes = frame . data re_img = np . frombuffer ( img_bytes , dtype = np . uint8 ) Returned frame from VideoLatestImage contains a data attribute. That's where our image is stored as BGR24 file. Since the data is stored as one dimensional byte buffer we need to convert the image into numpy array. After we converted the image into numpy array is easy to reshape that array into a decoded frame dimensions: # reshape image back into original dimensions if len ( frame . shape . dim ) > 0 : reshape = tuple ([ int ( dim . size ) for dim in frame . shape . dim ]) re_img = np . reshape ( re_img , reshape ) We end up with BGR24 image ready to be fed into any ML model or displayed with OpenCV as in our case: # display image cv2 . imshow ( 'box' , re_img )","title":"Code walkthrough"},{"location":"edge-proxy/examples/prerequsities/","text":"Python Examples prerequisites \u00b6 Install Anaconda environment All examples including the Anaconda environment descriptors can be found here: https://github.com/chryscloud/video-edge-ai-proxy/tree/master/examples Create Anaconda environment \u00b6 You can use this environment.yml descriptor for all documented examples: name: chrysedgeexamples channels: - conda-forge - peper0 dependencies: - python=3.7.7 - numpy=1.18.1 - pip=20.0.2 - opencv=4.4.0 - pip: - grpcio - grpcio-tools - imutils Create environment: conda create -f environment.yml Activate environment: conda activate chrysedgeexamples Build gRPC Client service \u00b6 Download proto file from here and put proto subfolder Build python client stubs: python3 -m grpc_tools.protoc -I proto/ --python_out=examples/ --grpc_python_out=examples/ proto/video_streaming.proto This should create 2 additional files in your \"examples\" folder: video_streaming_pb2.py and video_streaming_pb2_grpc.py You're ready to run some examples now!","title":"Prerequisites"},{"location":"edge-proxy/examples/prerequsities/#python-examples-prerequisites","text":"Install Anaconda environment All examples including the Anaconda environment descriptors can be found here: https://github.com/chryscloud/video-edge-ai-proxy/tree/master/examples","title":"Python Examples prerequisites"},{"location":"edge-proxy/examples/prerequsities/#create-anaconda-environment","text":"You can use this environment.yml descriptor for all documented examples: name: chrysedgeexamples channels: - conda-forge - peper0 dependencies: - python=3.7.7 - numpy=1.18.1 - pip=20.0.2 - opencv=4.4.0 - pip: - grpcio - grpcio-tools - imutils Create environment: conda create -f environment.yml Activate environment: conda activate chrysedgeexamples","title":"Create Anaconda environment"},{"location":"edge-proxy/examples/prerequsities/#build-grpc-client-service","text":"Download proto file from here and put proto subfolder Build python client stubs: python3 -m grpc_tools.protoc -I proto/ --python_out=examples/ --grpc_python_out=examples/ proto/video_streaming.proto This should create 2 additional files in your \"examples\" folder: video_streaming_pb2.py and video_streaming_pb2_grpc.py You're ready to run some examples now!","title":"Build gRPC Client service"},{"location":"edge-proxy/examples/probe/","text":"VideoProbe \u00b6 It's a simple request, response Unary RPC call. It returns basic codec information from specific camera. It also attached in-memory buffer information if exists. video_probe.py: import grpc import video_streaming_pb2_grpc , video_streaming_pb2 import argparse def gen_buffer_probe_request ( device_name ): \"\"\" Create GRPC request to get in memory probe info \"\"\" req = video_streaming_pb2 . VideoProbeRequest () req . device_id = device_name return req def gen_system_time_request (): return video_streaming_pb2 . SystemTimeRequest () if __name__ == \"__main__\" : parser = argparse . ArgumentParser ( description = 'Chrysalis Edge buffered images example' ) parser . add_argument ( \"--device\" , type = str , default = None , required = True ) args = parser . parse_args () device_id = args . device channel = grpc . insecure_channel ( '127.0.0.1:50001' ) stub = video_streaming_pb2_grpc . ImageStub ( channel ) probe = stub . VideoProbe ( gen_buffer_probe_request ( device_name = device_id )) print ( probe )","title":"Video Probe"},{"location":"edge-proxy/examples/probe/#videoprobe","text":"It's a simple request, response Unary RPC call. It returns basic codec information from specific camera. It also attached in-memory buffer information if exists. video_probe.py: import grpc import video_streaming_pb2_grpc , video_streaming_pb2 import argparse def gen_buffer_probe_request ( device_name ): \"\"\" Create GRPC request to get in memory probe info \"\"\" req = video_streaming_pb2 . VideoProbeRequest () req . device_id = device_name return req def gen_system_time_request (): return video_streaming_pb2 . SystemTimeRequest () if __name__ == \"__main__\" : parser = argparse . ArgumentParser ( description = 'Chrysalis Edge buffered images example' ) parser . add_argument ( \"--device\" , type = str , default = None , required = True ) args = parser . parse_args () device_id = args . device channel = grpc . insecure_channel ( '127.0.0.1:50001' ) stub = video_streaming_pb2_grpc . ImageStub ( channel ) probe = stub . VideoProbe ( gen_buffer_probe_request ( device_name = device_id )) print ( probe )","title":"VideoProbe"},{"location":"edge-proxy/examples/storage-onoff/","text":"Executing Storage On/Off script \u00b6 Storage example turns Chrysalis Cloud storage On or Off for the current live stream from the cameras. Run example to turn storage on for camera test : python storage_onoff.py --device test --on true Run example to turn storage off for camera test : python storage_onoff.py --device test --on false:","title":"Executing Storage On/Off script"},{"location":"edge-proxy/examples/storage-onoff/#executing-storage-onoff-script","text":"Storage example turns Chrysalis Cloud storage On or Off for the current live stream from the cameras. Run example to turn storage on for camera test : python storage_onoff.py --device test --on true Run example to turn storage off for camera test : python storage_onoff.py --device test --on false:","title":"Executing Storage On/Off script"},{"location":"edge-proxy/getting-started/docker-playbook/","text":"Docker Playbook \u00b6 How to show Chrys Edge logs \u00b6 sudo docker-compose logs How to stop / restart Chrys Edge \u00b6 #Go to the directory you ran install script (where your docker-compose.yml file is) # Stop container sudo docker - compose down # Stop all docker container sudo docker stop $ ( sudo docker ps - aq ) # If docker (and chrys edge) doesn't start at startup enable it sudo systemctl enable docker # Start container # detached mode sudo docker - compose up - d # interactive mode sudo docker - compose up # Restart container (after modifying the cong.yaml file for example) sudo docker - compose restart # Clear all docker container, images ... sudo docker system prune - a # Restart docker sudo service docker restart How to update Chrys Edge Version \u00b6 When newer version are available you can change the versions in the docker-compose.yml file and issue pull command: sudo docker-compose pull Alternatively you can repeat the installation process: curl -O https://raw.githubusercontent.com/chryscloud/api_doc/master/install-chrysedge.sh # Give exec permission chmod 777 install-chrysedge.sh # run installation script ./install-chrysedge.sh","title":"Docker Playbook"},{"location":"edge-proxy/getting-started/docker-playbook/#docker-playbook","text":"","title":"Docker Playbook"},{"location":"edge-proxy/getting-started/docker-playbook/#how-to-show-chrys-edge-logs","text":"sudo docker-compose logs","title":"How to show Chrys Edge logs"},{"location":"edge-proxy/getting-started/docker-playbook/#how-to-stop-restart-chrys-edge","text":"#Go to the directory you ran install script (where your docker-compose.yml file is) # Stop container sudo docker - compose down # Stop all docker container sudo docker stop $ ( sudo docker ps - aq ) # If docker (and chrys edge) doesn't start at startup enable it sudo systemctl enable docker # Start container # detached mode sudo docker - compose up - d # interactive mode sudo docker - compose up # Restart container (after modifying the cong.yaml file for example) sudo docker - compose restart # Clear all docker container, images ... sudo docker system prune - a # Restart docker sudo service docker restart","title":"How to stop / restart Chrys Edge"},{"location":"edge-proxy/getting-started/docker-playbook/#how-to-update-chrys-edge-version","text":"When newer version are available you can change the versions in the docker-compose.yml file and issue pull command: sudo docker-compose pull Alternatively you can repeat the installation process: curl -O https://raw.githubusercontent.com/chryscloud/api_doc/master/install-chrysedge.sh # Give exec permission chmod 777 install-chrysedge.sh # run installation script ./install-chrysedge.sh","title":"How to update Chrys Edge Version"},{"location":"edge-proxy/getting-started/other-cams/","text":"Other Cameras \u00b6 Currently other types of cameras are not supported. Drop us a note if it would be beneficial to support other than RTSP cameras. Contact us","title":"Connect Other Cameras"},{"location":"edge-proxy/getting-started/other-cams/#other-cameras","text":"Currently other types of cameras are not supported. Drop us a note if it would be beneficial to support other than RTSP cameras. Contact us","title":"Other Cameras"},{"location":"edge-proxy/getting-started/portal-usage/","text":"Connect your first RTSP Camera \u00b6 Open your browser and visit : http://localhost:8905 On the first visit, Edge Proxy will display a RTSP docker container icon. Click on it. This will initiate the pull for the latest version of the docker container pre-compiled to be used with RTSP enabled cameras. Connecting RTSP camera \u00b6 Name of the RTSP camera must be all ASCII letters Add your IP camera URL Example With credentials rtsp://admin:12345@192.168.1.21/Streaming/Channels/101 Example Without credentials rtsp://192.168.1.21:8554/unicast Click Add Chrysalis Portal \u00b6 You should see a similar image as bellow. The left black box is a log. Currently you need to manually refresh the website in order to see the log changes. The black box on the right is the error log. If there are no error logs the camera is succesfully connected. Next step Video API","title":"Connect RTSP Camera"},{"location":"edge-proxy/getting-started/portal-usage/#connect-your-first-rtsp-camera","text":"Open your browser and visit : http://localhost:8905 On the first visit, Edge Proxy will display a RTSP docker container icon. Click on it. This will initiate the pull for the latest version of the docker container pre-compiled to be used with RTSP enabled cameras.","title":"Connect your first RTSP Camera"},{"location":"edge-proxy/getting-started/portal-usage/#connecting-rtsp-camera","text":"Name of the RTSP camera must be all ASCII letters Add your IP camera URL Example With credentials rtsp://admin:12345@192.168.1.21/Streaming/Channels/101 Example Without credentials rtsp://192.168.1.21:8554/unicast Click Add","title":"Connecting RTSP camera"},{"location":"edge-proxy/getting-started/portal-usage/#chrysalis-portal","text":"You should see a similar image as bellow. The left black box is a log. Currently you need to manually refresh the website in order to see the log changes. The black box on the right is the error log. If there are no error logs the camera is succesfully connected. Next step Video API","title":"Chrysalis Portal"},{"location":"edge-proxy/getting-started/prerequisites/","text":"Prerequisites \u00b6 Before running and deploying this quickstart, install the Docker and docker-compose command: Install Docker of your operating system Install docker-compose on your operating system Enable docker TCP socket connection \u00b6 If you are running on Mac OS X or Windows use the latest version of docker-compose and docker. Linux Create daemon.json file in etc/docker folder with JSON contents: { \"hosts\": [ \"fd://\", \"unix:///var/run/docker.sock\" ] } If you're running Nvidia's docker containers make sure you don't remove the nvidia runtime: { \"hosts\": [ \"fd://\", \"unix:///var/run/docker.sock\" ], \"runtimes\": { \"nvidia\": { \"path\": \"nvidia-container-runtime\", \"runtimeArgs\": [] } } } Create a new file /etc/systemd/system/docker.service.d/docker.conf with the following contents: [Service] ExecStart= ExecStart=/usr/bin/dockerd Reload daemon: sudo systemctl daemon-reload Restart docker: sudo service docker restart Windows on WSL 2 It's recommended to download Docker Desktop Stable 2.3.0.2 or a later release Windows specific requirements: Install Windows 10, version 1903 or higher. Enable WSL 2 feature on Windows. For detailed instructions, refer to the Microsoft documentation. Download and install the Linux kernel update package. Mac OS X Follow the instructions for install docker engine: Docker Engine installation Docker Compose installation Raspberry PI TBD Nvidia Jetson TBD","title":"Before you begin"},{"location":"edge-proxy/getting-started/prerequisites/#prerequisites","text":"Before running and deploying this quickstart, install the Docker and docker-compose command: Install Docker of your operating system Install docker-compose on your operating system","title":"Prerequisites"},{"location":"edge-proxy/getting-started/prerequisites/#enable-docker-tcp-socket-connection","text":"If you are running on Mac OS X or Windows use the latest version of docker-compose and docker. Linux Create daemon.json file in etc/docker folder with JSON contents: { \"hosts\": [ \"fd://\", \"unix:///var/run/docker.sock\" ] } If you're running Nvidia's docker containers make sure you don't remove the nvidia runtime: { \"hosts\": [ \"fd://\", \"unix:///var/run/docker.sock\" ], \"runtimes\": { \"nvidia\": { \"path\": \"nvidia-container-runtime\", \"runtimeArgs\": [] } } } Create a new file /etc/systemd/system/docker.service.d/docker.conf with the following contents: [Service] ExecStart= ExecStart=/usr/bin/dockerd Reload daemon: sudo systemctl daemon-reload Restart docker: sudo service docker restart Windows on WSL 2 It's recommended to download Docker Desktop Stable 2.3.0.2 or a later release Windows specific requirements: Install Windows 10, version 1903 or higher. Enable WSL 2 feature on Windows. For detailed instructions, refer to the Microsoft documentation. Download and install the Linux kernel update package. Mac OS X Follow the instructions for install docker engine: Docker Engine installation Docker Compose installation Raspberry PI TBD Nvidia Jetson TBD","title":"Enable docker TCP socket connection"},{"location":"edge-proxy/getting-started/quick-start/","text":"Quick Start \u00b6 By default video-edge-ai-proxy requires these ports: 8905 for web portal 8909 for RESTful API (portal API) 50001 for client grpc connection 6379 for redis Make sure these ports are available before you start. Download installation script \u00b6 curl -O https://raw.githubusercontent.com/chryscloud/api_doc/master/install-chrysedge.sh # Give exec permission chmod 777 install-chrysedge.sh # run installation script ./install-chrysedge.sh Windows users should skip to Manual installation . Use Chrys Edge Proxy \u00b6 Start the docker images: docker - compose up # or to run it in daemon mode: docker - compose up - d Open browser and visit: http://localhost:8905 Next step: Connect RTSP Camera Manual installation \u00b6 It's recommended to create a folder where your user has sufficient permission. The recommended folder structure is: /home/yourusername/chrysedge |_/data |_/videos W where data and videos are subfolders of chrysedge Copy and paste below contents into a docker-compose.yml file and save it to /home/yourusername/chrysedge : version: '3.8' services: chrysedgeportal: image: chryscloud/chrysedgeportal:0.0.8 depends_on: - chrysedgeserver - redis ports: - \"8905:8905\" networks: - chrysnet chrysedgeserver: image: chryscloud/chrysedgeserver:0.0.8 restart: always depends_on: - redis entrypoint: /app/main ports: - \"8909:8909\" - \"50001:50001\" volumes: - TO_REPLACE_PATH_TO_USER_FOLDER:/data/chrysalis - /var/run/docker.sock:/var/run/docker.sock networks: - chrysnet redis: image: \"redis:alpine\" ports: - \"6379:6379\" networks: - chrysnet networks: chrysnet: name: chrysnet Change the folder TO_REPLACE_PATH_TO_USER_FOLDER with /home/yourusername/chrysedge","title":"Quick Start"},{"location":"edge-proxy/getting-started/quick-start/#quick-start","text":"By default video-edge-ai-proxy requires these ports: 8905 for web portal 8909 for RESTful API (portal API) 50001 for client grpc connection 6379 for redis Make sure these ports are available before you start.","title":"Quick Start"},{"location":"edge-proxy/getting-started/quick-start/#download-installation-script","text":"curl -O https://raw.githubusercontent.com/chryscloud/api_doc/master/install-chrysedge.sh # Give exec permission chmod 777 install-chrysedge.sh # run installation script ./install-chrysedge.sh Windows users should skip to Manual installation .","title":"Download installation script"},{"location":"edge-proxy/getting-started/quick-start/#use-chrys-edge-proxy","text":"Start the docker images: docker - compose up # or to run it in daemon mode: docker - compose up - d Open browser and visit: http://localhost:8905 Next step: Connect RTSP Camera","title":"Use Chrys Edge Proxy"},{"location":"edge-proxy/getting-started/quick-start/#manual-installation","text":"It's recommended to create a folder where your user has sufficient permission. The recommended folder structure is: /home/yourusername/chrysedge |_/data |_/videos W where data and videos are subfolders of chrysedge Copy and paste below contents into a docker-compose.yml file and save it to /home/yourusername/chrysedge : version: '3.8' services: chrysedgeportal: image: chryscloud/chrysedgeportal:0.0.8 depends_on: - chrysedgeserver - redis ports: - \"8905:8905\" networks: - chrysnet chrysedgeserver: image: chryscloud/chrysedgeserver:0.0.8 restart: always depends_on: - redis entrypoint: /app/main ports: - \"8909:8909\" - \"50001:50001\" volumes: - TO_REPLACE_PATH_TO_USER_FOLDER:/data/chrysalis - /var/run/docker.sock:/var/run/docker.sock networks: - chrysnet redis: image: \"redis:alpine\" ports: - \"6379:6379\" networks: - chrysnet networks: chrysnet: name: chrysnet Change the folder TO_REPLACE_PATH_TO_USER_FOLDER with /home/yourusername/chrysedge","title":"Manual installation"},{"location":"edge-proxy/grpc/annotate/","text":"Annotate \u00b6 Forwarding annotations to Chrysalis Cloud. Annotate object structure is compatible with Chrysalis Cloud and makes sure to forward the output annotations from your ML model into Chrysalis Annoation data warehouse, where they can be queried and analyized. Short Q&A \u00b6 Q: Do annoatation get forwarded even if the edge is offline? A: Yes. Annotations are temporarily stored on the edge until internet connecton is available, at which point all annotation get forwarded to Chrysalis Cloud. Proto Messages \u00b6 Request: AnnotateRequest Fields device_name string : required: The name of the camera you've setup in section Connect RTSP Camera remote_stream_id string : optional: if associated with storage, the ID of Chrysalis Cloud deviceID type string : required: event type: e.g. moving, exit, entry, stopped, parked, ... start_timestamp int64 : required: start of the event end_timestamp int64 : optional: end of the event object_type string : optional: e.g. person, car, face, bag, roadsign,... object_tracking_id string : optional: tracking id of the object confidence double : confidence of inference [0-1.0] Location Location : optional: object GEO location object_bouding_box BoudingBox : optional: object bounding box object_coordinate Coordinate : optional: object coordinates within the image mask repeated Coordinate : optional: object mask (polygon) object_signature repeated double : optional: signature of the detected item ml_model string : optional: description of the module that generated this event ml_model_version string : optional: version of the ML model width int32 : optional: image width height int32 : optional: optional: image height is_keyframe bool : optional: true/false if this annotation is from keyframe video_type string : optional: e.g. mp4 filename, live stream, ... offset_timestamp int64 : optional: offset from the beginning of the stream offset_duration int64 : optional: duration from the offset offset_frame_id int64 : optional: frame id within the packet offset_packet_id int64 : optional: packet id of withing the stream custom_meta_1 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) custom_meta_2 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) custom_meta_3 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) custom_meta_4 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) custom_meta_5 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) Response: AnnotateResponse Reponse serves and confirmation of the accepted Annotation request. Fields device_name string : required: The name of the camera you've setup in section Connect RTSP Camera remote_stream_id string : optional: if associated with storage, the ID of Chrysalis Cloud deviceID type string : event type: e.g. moving, exit, entry, stopped, parked, ... start_timestamp int64 : start of the event // Annotation messages message AnnotateRequest { string device_name = 1; // required: device name (required) identity of device string remote_stream_id = 2; //optional: if associated with storage, the ID of Chrysalis Cloud deviceID string type = 3; // required: event type: e.g. moving, exit, entry, stopped, parked, ... int64 start_timestamp = 4; //required: start of the event int64 end_timestamp = 5; // optional: event of the event string object_type = 6; // optional: e.g. person, car, face, bag, roadsign,... string object_id = 7; // optional: e.g. object id from the ML model string object_tracking_id = 8; // optional: tracking id of the object double confidence = 9; // confidence of inference [0-1.0] BoudingBox object_bouding_box = 10; // optional: object bounding box Location location = 11; // optional: object GEO location Coordinate object_coordinate = 12; // optional: object coordinates within the image repeated Coordinate mask = 13; // optional\" object mask (polygon) repeated double object_signature = 14; // optional: signature of the detected item string ml_model = 15; // optional: description of the module that generated this event string ml_model_version = 16; // optional: version of the ML model int32 width = 17; // optional: image width int32 height = 18; // optional: image height bool is_keyframe = 19; // optional: true/false if this annotation is from keyframe string video_type = 20; // optional: e.g. mp4 filename, live stream, ... int64 offset_timestamp = 21; // optional: offset from the beginning int64 offset_duration = 22; // optional: duration from the offset int64 offset_frame_id = 23; // optional: frame id of the int64 offset_packet_id = 24; // optional: offset of the packet // extending the event message meta data (optional) string custom_meta_1 = 25; // e.g. gender, hair, car model, ... string custom_meta_2 = 26; string custom_meta_3 = 27; string custom_meta_4 = 28; string custom_meta_5 = 29; } message AnnotateResponse { string device_name = 1; string remote_stream_id = 2; string type = 3; int64 start_timestamp = 4; }","title":"AI Tags:Annotations"},{"location":"edge-proxy/grpc/annotate/#annotate","text":"Forwarding annotations to Chrysalis Cloud. Annotate object structure is compatible with Chrysalis Cloud and makes sure to forward the output annotations from your ML model into Chrysalis Annoation data warehouse, where they can be queried and analyized.","title":"Annotate"},{"location":"edge-proxy/grpc/annotate/#short-qa","text":"Q: Do annoatation get forwarded even if the edge is offline? A: Yes. Annotations are temporarily stored on the edge until internet connecton is available, at which point all annotation get forwarded to Chrysalis Cloud.","title":"Short Q&amp;A"},{"location":"edge-proxy/grpc/annotate/#proto-messages","text":"Request: AnnotateRequest Fields device_name string : required: The name of the camera you've setup in section Connect RTSP Camera remote_stream_id string : optional: if associated with storage, the ID of Chrysalis Cloud deviceID type string : required: event type: e.g. moving, exit, entry, stopped, parked, ... start_timestamp int64 : required: start of the event end_timestamp int64 : optional: end of the event object_type string : optional: e.g. person, car, face, bag, roadsign,... object_tracking_id string : optional: tracking id of the object confidence double : confidence of inference [0-1.0] Location Location : optional: object GEO location object_bouding_box BoudingBox : optional: object bounding box object_coordinate Coordinate : optional: object coordinates within the image mask repeated Coordinate : optional: object mask (polygon) object_signature repeated double : optional: signature of the detected item ml_model string : optional: description of the module that generated this event ml_model_version string : optional: version of the ML model width int32 : optional: image width height int32 : optional: optional: image height is_keyframe bool : optional: true/false if this annotation is from keyframe video_type string : optional: e.g. mp4 filename, live stream, ... offset_timestamp int64 : optional: offset from the beginning of the stream offset_duration int64 : optional: duration from the offset offset_frame_id int64 : optional: frame id within the packet offset_packet_id int64 : optional: packet id of withing the stream custom_meta_1 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) custom_meta_2 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) custom_meta_3 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) custom_meta_4 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) custom_meta_5 string : optional: extending the event message meta data (e.g. gender, hair, car model, ...) Response: AnnotateResponse Reponse serves and confirmation of the accepted Annotation request. Fields device_name string : required: The name of the camera you've setup in section Connect RTSP Camera remote_stream_id string : optional: if associated with storage, the ID of Chrysalis Cloud deviceID type string : event type: e.g. moving, exit, entry, stopped, parked, ... start_timestamp int64 : start of the event // Annotation messages message AnnotateRequest { string device_name = 1; // required: device name (required) identity of device string remote_stream_id = 2; //optional: if associated with storage, the ID of Chrysalis Cloud deviceID string type = 3; // required: event type: e.g. moving, exit, entry, stopped, parked, ... int64 start_timestamp = 4; //required: start of the event int64 end_timestamp = 5; // optional: event of the event string object_type = 6; // optional: e.g. person, car, face, bag, roadsign,... string object_id = 7; // optional: e.g. object id from the ML model string object_tracking_id = 8; // optional: tracking id of the object double confidence = 9; // confidence of inference [0-1.0] BoudingBox object_bouding_box = 10; // optional: object bounding box Location location = 11; // optional: object GEO location Coordinate object_coordinate = 12; // optional: object coordinates within the image repeated Coordinate mask = 13; // optional\" object mask (polygon) repeated double object_signature = 14; // optional: signature of the detected item string ml_model = 15; // optional: description of the module that generated this event string ml_model_version = 16; // optional: version of the ML model int32 width = 17; // optional: image width int32 height = 18; // optional: image height bool is_keyframe = 19; // optional: true/false if this annotation is from keyframe string video_type = 20; // optional: e.g. mp4 filename, live stream, ... int64 offset_timestamp = 21; // optional: offset from the beginning int64 offset_duration = 22; // optional: duration from the offset int64 offset_frame_id = 23; // optional: frame id of the int64 offset_packet_id = 24; // optional: offset of the packet // extending the event message meta data (optional) string custom_meta_1 = 25; // e.g. gender, hair, car model, ... string custom_meta_2 = 26; string custom_meta_3 = 27; string custom_meta_4 = 28; string custom_meta_5 = 29; } message AnnotateResponse { string device_name = 1; string remote_stream_id = 2; string type = 3; int64 start_timestamp = 4; }","title":"Proto Messages"},{"location":"edge-proxy/grpc/list_streams/","text":"ListStreams \u00b6 ListStream returns the list of all connected cameras. Proto Messages \u00b6 Requires empty request Request: ListStreamRequest Fields Response: ListStream Fields name string : The name of the camera you've setup in section Connect RTSP Camera status string : running, restarting, failed, stopped failing_streak int64 : number of failed attempts to connect to camera health_status string : deprecated dead bool : process is dead exit_code int64 : process exit code pid int32 : process PID running bool : True if camera is up and running paused bool : True if process is paused restarting bool : True if process is restarting oomkilled bool : True if process is OOM killed error string : Failure description // ListStream messages message ListStream { string name = 1; string status = 2; int64 failing_streak = 3; string health_status = 4; bool dead = 5; int64 exit_code = 6; int32 pid = 7; bool running = 8; bool paused = 9; bool restarting = 10; bool oomkilled = 11; string error = 12; } message ListStreamRequest { }","title":"ListStreams"},{"location":"edge-proxy/grpc/list_streams/#liststreams","text":"ListStream returns the list of all connected cameras.","title":"ListStreams"},{"location":"edge-proxy/grpc/list_streams/#proto-messages","text":"Requires empty request Request: ListStreamRequest Fields Response: ListStream Fields name string : The name of the camera you've setup in section Connect RTSP Camera status string : running, restarting, failed, stopped failing_streak int64 : number of failed attempts to connect to camera health_status string : deprecated dead bool : process is dead exit_code int64 : process exit code pid int32 : process PID running bool : True if camera is up and running paused bool : True if process is paused restarting bool : True if process is restarting oomkilled bool : True if process is OOM killed error string : Failure description // ListStream messages message ListStream { string name = 1; string status = 2; int64 failing_streak = 3; string health_status = 4; bool dead = 5; int64 exit_code = 6; int32 pid = 7; bool running = 8; bool paused = 9; bool restarting = 10; bool oomkilled = 11; string error = 12; } message ListStreamRequest { }","title":"Proto Messages"},{"location":"edge-proxy/grpc/prerequisites/","text":"Chrysalis Edge Video API \u00b6 Access to connected cameras video streams. gRPC \u00b6 gRPC can use protocol buffers as both its Interface Definition Language (IDL) and as its underlying message interchange format. If you\u2019re new to gRPC and/or protocol buffers, read this! Package chrys.cloud.videostreaming.v1beta1 \u00b6 Service overview: service Image { rpc VideoLatestImage(stream VideoFrameRequest) returns (stream VideoFrame) {} rpc VideoBufferedImage(VideoFrameBufferedRequest) returns (stream VideoFrame) {} rpc VideoProbe(VideoProbeRequest) returns (VideoProbeResponse) {} rpc ListStreams(ListStreamRequest) returns (stream ListStream) {} rpc Annotate(AnnotateRequest) returns (AnnotateResponse) {} rpc Proxy(ProxyRequest) returns (ProxyResponse) {} // start stop rtmp passthrough rpc Storage(StorageRequest) returns (StorageResponse) {} // start stop storage request on the Chrysalis servers rpc SystemTime(SystemTimeRequest) returns (SystemTimeResponse) {} // returns current system time } To see complete proto file click here Index \u00b6","title":"Overview"},{"location":"edge-proxy/grpc/prerequisites/#chrysalis-edge-video-api","text":"Access to connected cameras video streams.","title":"Chrysalis Edge Video API"},{"location":"edge-proxy/grpc/prerequisites/#grpc","text":"gRPC can use protocol buffers as both its Interface Definition Language (IDL) and as its underlying message interchange format. If you\u2019re new to gRPC and/or protocol buffers, read this!","title":"gRPC"},{"location":"edge-proxy/grpc/prerequisites/#package-chryscloudvideostreamingv1beta1","text":"Service overview: service Image { rpc VideoLatestImage(stream VideoFrameRequest) returns (stream VideoFrame) {} rpc VideoBufferedImage(VideoFrameBufferedRequest) returns (stream VideoFrame) {} rpc VideoProbe(VideoProbeRequest) returns (VideoProbeResponse) {} rpc ListStreams(ListStreamRequest) returns (stream ListStream) {} rpc Annotate(AnnotateRequest) returns (AnnotateResponse) {} rpc Proxy(ProxyRequest) returns (ProxyResponse) {} // start stop rtmp passthrough rpc Storage(StorageRequest) returns (StorageResponse) {} // start stop storage request on the Chrysalis servers rpc SystemTime(SystemTimeRequest) returns (SystemTimeResponse) {} // returns current system time } To see complete proto file click here","title":"Package chrys.cloud.videostreaming.v1beta1"},{"location":"edge-proxy/grpc/prerequisites/#index","text":"","title":"Index"},{"location":"edge-proxy/grpc/proxy/","text":"Proxy \u00b6 On/Off switch for forwarding video stream to Chrysalis Cloud for further video analysis in the cloud. Proto Messages \u00b6 Request: ProxyRequest Fields device_id string : required: The name of the camera you've setup in section Connect RTSP Camera passthrough bool : true = passthrough streaming, false = stop passthrough streaming Response: ProxyResponse Fields device_id string : required: The name of the camera you've setup in section Connect RTSP Camera passthrough bool : true = passthrough streaming, false = stop passthrough streaming // Proxy messages message ProxyRequest { string device_id = 1; bool passthrough = 2; // true = passthrough streaming, false = stop passthrough streaming } message ProxyResponse { string device_id = 1; bool passthrough = 2; }","title":"Proxy to cloud"},{"location":"edge-proxy/grpc/proxy/#proxy","text":"On/Off switch for forwarding video stream to Chrysalis Cloud for further video analysis in the cloud.","title":"Proxy"},{"location":"edge-proxy/grpc/proxy/#proto-messages","text":"Request: ProxyRequest Fields device_id string : required: The name of the camera you've setup in section Connect RTSP Camera passthrough bool : true = passthrough streaming, false = stop passthrough streaming Response: ProxyResponse Fields device_id string : required: The name of the camera you've setup in section Connect RTSP Camera passthrough bool : true = passthrough streaming, false = stop passthrough streaming // Proxy messages message ProxyRequest { string device_id = 1; bool passthrough = 2; // true = passthrough streaming, false = stop passthrough streaming } message ProxyResponse { string device_id = 1; bool passthrough = 2; }","title":"Proto Messages"},{"location":"edge-proxy/grpc/remote_storage/","text":"Remote Storage \u00b6 Turning cloud storage on and off for a specific device/camera. If storage is ON, then the stream is being forwarded to the Chrysalis Cloud where it's being stored. Proto Messages \u00b6 Request: StorageRequest Fields device_id string : required: The name of the camera you've setup in section Connect RTSP Camera start bool : true = start storing the stream, false = stop storing the stream Response: StorageResponse Fields device_id string : required: The name of the camera you've setup in section Connect RTSP Camera start bool : true = start storing the stream, false = stop storing the stream // Storage messages message StorageRequest { string device_id = 1; bool start = 2; } message StorageResponse { string device_id = 1; bool start = 2; }","title":"Remote Storage"},{"location":"edge-proxy/grpc/remote_storage/#remote-storage","text":"Turning cloud storage on and off for a specific device/camera. If storage is ON, then the stream is being forwarded to the Chrysalis Cloud where it's being stored.","title":"Remote Storage"},{"location":"edge-proxy/grpc/remote_storage/#proto-messages","text":"Request: StorageRequest Fields device_id string : required: The name of the camera you've setup in section Connect RTSP Camera start bool : true = start storing the stream, false = stop storing the stream Response: StorageResponse Fields device_id string : required: The name of the camera you've setup in section Connect RTSP Camera start bool : true = start storing the stream, false = stop storing the stream // Storage messages message StorageRequest { string device_id = 1; bool start = 2; } message StorageResponse { string device_id = 1; bool start = 2; }","title":"Proto Messages"},{"location":"edge-proxy/grpc/system_time/","text":"SystemTime \u00b6 Chrysalis Edge system time. Addressing possible clock drifts between systems. This will be deprecated in the future in favor of VideoProbe message SystemTimeResponse { int64 current_time = 1; } message SystemTimeRequest {}","title":"System Time"},{"location":"edge-proxy/grpc/system_time/#systemtime","text":"Chrysalis Edge system time. Addressing possible clock drifts between systems. This will be deprecated in the future in favor of VideoProbe message SystemTimeResponse { int64 current_time = 1; } message SystemTimeRequest {}","title":"SystemTime"},{"location":"edge-proxy/grpc/video_buffered_image/","text":"VideoBufferedImage \u00b6 VideoBufferedImage retrieves video frames from buffer. It works well in conjunction with VideoProbe which outputs information on the in memory buffer details. Proto Messages \u00b6 Request: VideoFrameBufferedRequest Fields device_id string : The name of the camera you've setup in section Connect RTSP Camera timestamp_from int64 : Start point in time in the buffer (in milliseconds) timestamp_to int64 : End point in time in the buffer (in milliseconds) Response: VideoFrame","title":"VideoBufferedImage"},{"location":"edge-proxy/grpc/video_buffered_image/#videobufferedimage","text":"VideoBufferedImage retrieves video frames from buffer. It works well in conjunction with VideoProbe which outputs information on the in memory buffer details.","title":"VideoBufferedImage"},{"location":"edge-proxy/grpc/video_buffered_image/#proto-messages","text":"Request: VideoFrameBufferedRequest Fields device_id string : The name of the camera you've setup in section Connect RTSP Camera timestamp_from int64 : Start point in time in the buffer (in milliseconds) timestamp_to int64 : End point in time in the buffer (in milliseconds) Response: VideoFrame","title":"Proto Messages"},{"location":"edge-proxy/grpc/video_latest_image/","text":"VideoLatestImage \u00b6 VideoLatestImage is specifically designed to return a decoded image in bgr24 format in sequential order as seen from camera stream. It's purpose is to feed the image into any inference ML model for AI insight and video analytics. Although it can also be used for display purposes. Short Q&A \u00b6 Q: What if my ML inference engine can't process all frames from live stream? A: : The API is designed to analize video in real time therefor it will drop all \"expired\" frames (oldest frames that might overflow the internal queue) and feed only the current frames from camera. The emphasis is on live stream. Q: What is I'd like to be able to process all frames from the camera? A: : As long as you frequently query this API you should be able to retrieve all frames produced by your camera. This is true as long the internal queue doesn't get full at which point the frame dropping begins. If you'd like to \"catch-up\" on a stream but not drop any frames look into configuring an in memory buffer and define it's length in frames. Check also VideoBufferedImage Q: What if my inference engine is faster than camera produces video frames? A: The query will wait for maximum of 16*3 milliseconds. If the new frame from the camera doesn't appear it will return empty Data . Q: Does VideoLatestImage return duplicate images? A: No. VideoLatestImage remembers the point in time of the last returned frame. Next query will return new image. Q: Is there a limit on number of queries? A: No. You can query as fast as you can. Response times are optimized for you to be able to simply query multiple connected cameras also. Proto Messages \u00b6 The request message for latest decoded video frame from specific camera: VideoFrameRequest Request: VideoFrameRequest Fields device_id string : The name of the camera you've setup in section Connect RTSP Camera key_frame_only string : Decode only key frames from camera you've setup in section Connect RTSP Camera Response message VideoFrame Fields width int64 : the width of the ingested video height int64 : the height of the ingested video data bytes : decoded video frame ( BGR24 ) is_keyframe bool : If the returned image was decoed from keyframe pts int64 : decoding timestamp dts int64 : presentation timestamp frame_type string : I, P, B frame is_corrupt string : if decoding produced a corrupt image time_base double : decoder use for knowing the time lag between frames device_id string : the name of the camera packet int64 : the packet index extradata bytes : custom extra data attached to the frame codec_name string : name of the codec used to decode a frame pix_fmt string : pixel format of compressed stream Proto message: message VideoFrame { int64 width = 1; int64 height = 2; bytes data = 3; int64 timestamp = 4; bool is_keyframe = 5; int64 pts = 6; int64 dts = 7; string frame_type = 8; bool is_corrupt = 9; double time_base = 10; ShapeProto shape = 11; string device_id = 12; int64 packet = 13; int64 keyframe = 14; bytes extradata = 15; string codec_name = 16; string pix_fmt = 17; } message VideoFrameRequest { bool key_frame_only = 1; string device_id = 2; }","title":"VideoLatestImage"},{"location":"edge-proxy/grpc/video_latest_image/#videolatestimage","text":"VideoLatestImage is specifically designed to return a decoded image in bgr24 format in sequential order as seen from camera stream. It's purpose is to feed the image into any inference ML model for AI insight and video analytics. Although it can also be used for display purposes.","title":"VideoLatestImage"},{"location":"edge-proxy/grpc/video_latest_image/#short-qa","text":"Q: What if my ML inference engine can't process all frames from live stream? A: : The API is designed to analize video in real time therefor it will drop all \"expired\" frames (oldest frames that might overflow the internal queue) and feed only the current frames from camera. The emphasis is on live stream. Q: What is I'd like to be able to process all frames from the camera? A: : As long as you frequently query this API you should be able to retrieve all frames produced by your camera. This is true as long the internal queue doesn't get full at which point the frame dropping begins. If you'd like to \"catch-up\" on a stream but not drop any frames look into configuring an in memory buffer and define it's length in frames. Check also VideoBufferedImage Q: What if my inference engine is faster than camera produces video frames? A: The query will wait for maximum of 16*3 milliseconds. If the new frame from the camera doesn't appear it will return empty Data . Q: Does VideoLatestImage return duplicate images? A: No. VideoLatestImage remembers the point in time of the last returned frame. Next query will return new image. Q: Is there a limit on number of queries? A: No. You can query as fast as you can. Response times are optimized for you to be able to simply query multiple connected cameras also.","title":"Short Q&amp;A"},{"location":"edge-proxy/grpc/video_latest_image/#proto-messages","text":"The request message for latest decoded video frame from specific camera: VideoFrameRequest Request: VideoFrameRequest Fields device_id string : The name of the camera you've setup in section Connect RTSP Camera key_frame_only string : Decode only key frames from camera you've setup in section Connect RTSP Camera Response message VideoFrame Fields width int64 : the width of the ingested video height int64 : the height of the ingested video data bytes : decoded video frame ( BGR24 ) is_keyframe bool : If the returned image was decoed from keyframe pts int64 : decoding timestamp dts int64 : presentation timestamp frame_type string : I, P, B frame is_corrupt string : if decoding produced a corrupt image time_base double : decoder use for knowing the time lag between frames device_id string : the name of the camera packet int64 : the packet index extradata bytes : custom extra data attached to the frame codec_name string : name of the codec used to decode a frame pix_fmt string : pixel format of compressed stream Proto message: message VideoFrame { int64 width = 1; int64 height = 2; bytes data = 3; int64 timestamp = 4; bool is_keyframe = 5; int64 pts = 6; int64 dts = 7; string frame_type = 8; bool is_corrupt = 9; double time_base = 10; ShapeProto shape = 11; string device_id = 12; int64 packet = 13; int64 keyframe = 14; bytes extradata = 15; string codec_name = 16; string pix_fmt = 17; } message VideoFrameRequest { bool key_frame_only = 1; string device_id = 2; }","title":"Proto Messages"},{"location":"edge-proxy/grpc/video_probe/","text":"VideoProbe \u00b6 VideProbe returns basic codec information from specific camera. It also attached in-memory buffer information if exists. Proto Messages \u00b6 Request: VideoProbeRequest Fields device_id string : The name of the camera you've setup in section Connect RTSP Camera Response: VideoProbeResponse Fields video_codec VideoCodec : basic video information (width, height, ...) buffer VideoBuffer : basic video buffer information message VideoProbeRequest { string device_id = 1; } message VideoProbeResponse { VideoCodec video_codec = 1; VideoBuffer buffer = 2; } message VideoBuffer { int64 start_time = 1; int64 end_time = 2; int64 duration_seconds = 3; int32 approximate_fps = 4; int64 frames = 5; } // VideoCodec information about the stream message VideoCodec { string name = 1; int32 width = 2; int32 height = 3; string pix_fmt = 4; bytes extradata = 5; int32 extradata_size = 6; string long_name = 7; }","title":"VideoProbe"},{"location":"edge-proxy/grpc/video_probe/#videoprobe","text":"VideProbe returns basic codec information from specific camera. It also attached in-memory buffer information if exists.","title":"VideoProbe"},{"location":"edge-proxy/grpc/video_probe/#proto-messages","text":"Request: VideoProbeRequest Fields device_id string : The name of the camera you've setup in section Connect RTSP Camera Response: VideoProbeResponse Fields video_codec VideoCodec : basic video information (width, height, ...) buffer VideoBuffer : basic video buffer information message VideoProbeRequest { string device_id = 1; } message VideoProbeResponse { VideoCodec video_codec = 1; VideoBuffer buffer = 2; } message VideoBuffer { int64 start_time = 1; int64 end_time = 2; int64 duration_seconds = 3; int32 approximate_fps = 4; int64 frames = 5; } // VideoCodec information about the stream message VideoCodec { string name = 1; int32 width = 2; int32 height = 3; string pix_fmt = 4; bytes extradata = 5; int32 extradata_size = 6; string long_name = 7; }","title":"Proto Messages"}]}